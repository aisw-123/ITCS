{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, makedirs\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "For the given path, get the List of all files in the directory tree \n",
    "https://thispointer.com/python-how-to-get-list-of-files-in-directory-and-sub-directories/\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def GetFileList(dirName, endings=[\".jpg\", \".jpeg\", \".png\", \".mp4\"]):\n",
    "    # create a list of file and sub directories\n",
    "    # names in the given directory\n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    # Make sure all file endings start with a '.'\n",
    "\n",
    "    for i, ending in enumerate(endings):\n",
    "        if ending[0] != \".\":\n",
    "            endings[i] = \".\" + ending\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        # If entry is a directory then get the list of files in this directory\n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + GetFileList(fullPath, endings)\n",
    "        else:\n",
    "            for ending in endings:\n",
    "                if entry.endswith(ending):\n",
    "                    allFiles.append(fullPath)\n",
    "    return allFiles\n",
    "\n",
    "\n",
    "def ChangeToOtherMachine(filelist, repo=\"TrainYourOwnYOLO\", remote_machine=\"\"):\n",
    "    \"\"\"\n",
    "    Takes a list of file_names located in a repo and changes it to the local machines file names. File must be executed from withing the repository\n",
    "    Example:\n",
    "    '/home/ubuntu/TrainYourOwnYOLO/Data/Street_View_Images/vulnerable/test.jpg'\n",
    "    Get's converted to\n",
    "    \n",
    "    'C:/Users/Anton/TrainYourOwnYOLO/Data/Street_View_Images/vulnerable/test.jpg'\n",
    "    \"\"\"\n",
    "    filelist = [x.replace(\"\\\\\", \"/\") for x in filelist]\n",
    "    if repo[-1] == \"/\":\n",
    "        repo = repo[:-1]\n",
    "    if remote_machine:\n",
    "        prefix = remote_machine.replace(\"\\\\\", \"/\")\n",
    "    else:\n",
    "        prefix = ((os.path.dirname(os.path.abspath(__file__)).split(repo))[0]).replace(\n",
    "            \"\\\\\", \"/\"\n",
    "        )\n",
    "    new_list = []\n",
    "\n",
    "    for file in filelist:\n",
    "        suffix = (file.split(repo))[1]\n",
    "        if suffix[0] == \"/\":\n",
    "            suffix = suffix[1:]\n",
    "        new_list.append(os.path.join(prefix, repo + \"/\", suffix).replace(\"\\\\\", \"/\"))\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'C:\\\\Users\\\\Desktop\\\\Dataset-SWImages\\\\vott-csv-export' does not exist: b'C:\\\\Users\\\\Desktop\\\\Dataset-SWImages\\\\vott-csv-export'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-0114dcbdae57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[0mlabeldict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     multi_df = pd.read_csv(\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[1;34m\"C:\\\\Users\\\\Desktop\\\\Dataset-SWImages\\\\vott-csv-export\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    189\u001b[0m     \u001b[0mmulti_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"first\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'C:\\\\Users\\\\Desktop\\\\Dataset-SWImages\\\\vott-csv-export' does not exist: b'C:\\\\Users\\\\Desktop\\\\Dataset-SWImages\\\\vott-csv-export'"
     ]
    }
   ],
   "source": [
    "from os import path, makedirs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def convert_vott_csv_to_yolo(\n",
    "    vott_df,\n",
    "    labeldict,\n",
    "    path=\"\",\n",
    "    target_name=\"data_train.txt\",\n",
    "    abs_path=False,\n",
    "):\n",
    "\n",
    "    # Encode labels according to labeldict if code's don't exist\n",
    "    label_names = [\n",
    "        \"Standing\",\n",
    "        \"Walking\" ]\n",
    "    if not \"code\" in vott_df.columns:\n",
    "        vott_df[\"code\"] = vott_df[\"label\"].apply(lambda x: labeldict[x])\n",
    "    # Round float to ints\n",
    "    for col in vott_df[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]]:\n",
    "        vott_df[col] = (vott_df[col]).apply(lambda x: round(x))\n",
    "\n",
    "    # Create Yolo Text file\n",
    "    last_image = \"\"\n",
    "    txt_file = \"\"\n",
    "\n",
    "    for index, row in vott_df.iterrows():\n",
    "        if not last_image == row[\"image\"]:\n",
    "            if abs_path:\n",
    "                txt_file += \"\\n\" + row[\"image_path\"] + \" \"\n",
    "            else:\n",
    "                txt_file += \"\\n\" + os.path.join(path, row[\"image\"]) + \" \"\n",
    "            txt_file += \",\".join(\n",
    "                [\n",
    "                    str(x)\n",
    "                    for x in (row[[\"xmin\", \"ymin\", \"xmax\", \"ymax\", \"code\"]].tolist())\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            txt_file += \" \"\n",
    "            txt_file += \",\".join(\n",
    "                [\n",
    "                    str(x)\n",
    "                    for x in (row[[\"xmin\", \"ymin\", \"xmax\", \"ymax\", \"code\"]].tolist())\n",
    "                ]\n",
    "            )\n",
    "        last_image = row[\"image\"]\n",
    "    file = open(target_name, \"w\")\n",
    "    file.write(txt_file[1:])\n",
    "    file.close()\n",
    "    return True\n",
    "\n",
    "\n",
    "def csv_from_xml(directory, path_name=\"\"):\n",
    "    # First get all images and xml files from path and its subfolders\n",
    "    label_names = [\n",
    "        \"Standing\",\n",
    "        \"Walking\" ]\n",
    "    image_paths = GetFileList(directory, \".jpg\")\n",
    "    xml_paths = GetFileList(directory, \".xml\")\n",
    "    result_df = pd.DataFrame()\n",
    "    if not len(image_paths) == len(xml_paths):\n",
    "        print(\"number of annotations doesnt match number of images\")\n",
    "        return False\n",
    "    for image in image_paths:\n",
    "        target_filename = os.path.join(path_name, image) if path_name else image\n",
    "        source_filename = os.path.join(directory, image)\n",
    "        y_size, x_size, _ = np.array(Image.open(source_filename)).shape\n",
    "        source_xml = image.replace(\".jpg\", \".xml\")\n",
    "        txt = open(source_xml, \"r\").read()\n",
    "        y_vals = re.findall(r\"(?:x>\\n)(.*)(?:\\n</)\", txt)\n",
    "        ymin_vals = y_vals[::2]\n",
    "        ymax_vals = y_vals[1::2]\n",
    "        x_vals = re.findall(r\"(?:y>\\n)(.*)(?:\\n</)\", txt)\n",
    "        xmin_vals = x_vals[::2]\n",
    "        xmax_vals = x_vals[1::2]\n",
    "        label_vals = re.findall(r\"(?:label>\\n)(.*)(?:\\n</)\", txt)\n",
    "        label_name_vals = re.findall(r\"(?:labelname>\\n)(.*)(?:\\n</)\", txt)\n",
    "        df = pd.DataFrame()\n",
    "        df[\"xmin\"] = xmin_vals\n",
    "        df[\"xmin\"] = df[\"xmin\"].astype(float) * x_size\n",
    "        df[\"ymin\"] = ymin_vals\n",
    "        df[\"ymin\"] = df[\"ymin\"].astype(float) * y_size\n",
    "        df[\"xmax\"] = xmax_vals\n",
    "        df[\"xmax\"] = df[\"xmax\"].astype(float) * x_size\n",
    "        df[\"ymax\"] = ymax_vals\n",
    "        df[\"ymax\"] = df[\"ymax\"].astype(float) * y_size\n",
    "        df[\"label\"] = label_name_vals\n",
    "        df[\"code\"] = label_vals\n",
    "        df[\"image_path\"] = target_filename\n",
    "        df[\"image\"] = os.path.basename(target_filename)\n",
    "        result_df = result_df.append(df)\n",
    "    #     Bring image column first\n",
    "    cols = list(df.columns)\n",
    "    cols = [cols[-1]] + cols[:-1]\n",
    "    result_df = result_df[cols]\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def crop_and_save(\n",
    "    image_df,\n",
    "    target_path,\n",
    "    target_file,\n",
    "    one=True,\n",
    "    label_dict={0: \"house\"},\n",
    "    postfix=\"cropped\",\n",
    "):\n",
    "    \"\"\"Takes a vott_csv file with image names, labels and crop_boxes\n",
    "    and crops the images accordingly\n",
    "    \n",
    "    Input csv file format:\n",
    "    \n",
    "    image   xmin ymin xmax ymax label\n",
    "    im.jpg  0    10   100  500  house\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.Dataframe \n",
    "        The input dataframe with file_names, bounding box info\n",
    "        and label\n",
    "    source_path : str\n",
    "        Path of source images\n",
    "    target_path : str, optional\n",
    "        Path to save cropped images\n",
    "    one : boolean, optional\n",
    "        if True, only the most central house will be returned\n",
    "    Returns\n",
    "    -------\n",
    "    True if completed succesfully\n",
    "    \"\"\"\n",
    "    if not path.isdir(target_path):\n",
    "        makedirs(target_path)\n",
    "\n",
    "    previous_name = \"\"\n",
    "    counter = 0\n",
    "    image_df.dropna(inplace=True)\n",
    "    image_df[\"image_path\"] = ChangeToOtherMachine(image_df[\"image_path\"].values)\n",
    "\n",
    "    def find_rel_position(row):\n",
    "        current_name = row[\"image_path\"]\n",
    "        x_size, _ = Image.open(current_name).size\n",
    "        x_centrality = abs((row[\"xmin\"] + row[\"xmax\"]) / 2 / x_size - 0.5)\n",
    "        return x_centrality\n",
    "\n",
    "    if one:\n",
    "        centrality = []\n",
    "        for index, row in image_df.iterrows():\n",
    "            centrality.append(find_rel_position(row))\n",
    "        image_df[\"x_centrality\"] = pd.Series(centrality)\n",
    "        image_df.sort_values([\"image\", \"x_centrality\"], inplace=True)\n",
    "        image_df.drop_duplicates(subset=\"image\", keep=\"first\", inplace=True)\n",
    "    new_paths = []\n",
    "    for index, row in image_df.iterrows():\n",
    "        current_name = row[\"image_path\"]\n",
    "        if current_name == previous_name:\n",
    "            counter += 1\n",
    "        else:\n",
    "            counter = 0\n",
    "        imageObject = Image.open(current_name)\n",
    "        cropped = imageObject.crop((row[\"xmin\"], row[\"ymin\"], row[\"xmax\"], row[\"ymax\"]))\n",
    "        label = row[\"label\"]\n",
    "        if type(label) == int:\n",
    "            label = label_dict[label]\n",
    "        image_name_cropped = (\n",
    "            \"_\".join([row[\"image\"][:-4], postfix, label, str(counter)]) + \".jpg\"\n",
    "        )\n",
    "        new_path = os.path.join(target_path, image_name_cropped)\n",
    "        cropped.save(new_path)\n",
    "        new_paths.append(new_path.replace(\"\\\\\", \"/\"))\n",
    "        previous_name = current_name\n",
    "    pd.DataFrame(new_paths, columns=[\"image_path\"]).to_csv(target_file)\n",
    "    return True\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Prepare the houses dataset for YOLO\n",
    "    label_names = [\n",
    "        \"Standing\",\n",
    "        \"Walking\" ]\n",
    "    num_list=[1,2]\n",
    "    labeldict = dict(zip(label_names, num_list))\n",
    "    multi_df = pd.read_csv(\n",
    "        \"C:\\\\Users\\\\Desktop\\\\Dataset-SWImages\\\\vott-csv-export\"\n",
    "    )\n",
    "    multi_df.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
    "    convert_vott_csv_to_yolo(\n",
    "        multi_df,\n",
    "        labeldict,\n",
    "        path=\"C:\\\\Users\\\\Desktop\\\\Dataset-SWImages\",\n",
    "        target_name=\"data_train.txt\",\n",
    "    )\n",
    "\n",
    "    path=\"C:\\\\Users\\\\Desktop\\\\Dataset-SWImages\"\n",
    "    label_names = [\n",
    "        \"Standing\",\n",
    "        \"Walking\" ,]\n",
    "    convert_vott_csv_to_yolo(\n",
    "        csv_from_xml(path, \"C:\\\\Users\\\\Desktop\\\\Dataset-SWImages\"), labeldict\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Convert_Format'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-267c885ebbfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\pmdna\\\\Desktop\\\\Dataset-SWImages\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Utils\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mConvert_Format\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconvert_vott_csv_to_yolo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mData_Folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_parent_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Convert_Format'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from os import path, makedirs\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "\n",
    "sys.path.append(os.path.join(\"C:\\\\Users\\\\pmdna\\\\Desktop\\\\Dataset-SWImages\", \"Utils\"))\n",
    "from Convert_Format import convert_vott_csv_to_yolo\n",
    "\n",
    "Data_Folder = os.path.join(get_parent_dir(1), \"Data\")\n",
    "VoTT_Folder = os.path.join(\n",
    "    Data_Folder, \"Source_Images\", \"Training_Images\", \"vott-csv-export\"\n",
    ")\n",
    "VoTT_csv = os.path.join(VoTT_Folder, \"Annotations-export.csv\")\n",
    "YOLO_filename = os.path.join(VoTT_Folder, \"data_train.txt\")\n",
    "\n",
    "model_folder = os.path.join(Data_Folder, \"Model_Weights\")\n",
    "classes_filename = os.path.join(model_folder, \"data_classes.txt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # surpress any inhereted default values\n",
    "    parser = argparse.ArgumentParser(argument_default=argparse.SUPPRESS)\n",
    "    \"\"\"\n",
    "    Command line options\n",
    "    \"\"\"\n",
    "    parser.add_argument(\n",
    "        \"--VoTT_Folder\",\n",
    "        type=str,\n",
    "        default=VoTT_Folder,\n",
    "        help=\"Absolute path to the exported files from the image tagging step with VoTT. Default is \"\n",
    "        + VoTT_Folder,\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--VoTT_csv\",\n",
    "        type=str,\n",
    "        default=VoTT_csv,\n",
    "        help=\"Absolute path to the *.csv file exported from VoTT. Default is \"\n",
    "        + VoTT_csv,\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--YOLO_filename\",\n",
    "        type=str,\n",
    "        default=YOLO_filename,\n",
    "        help=\"Absolute path to the file where the annotations in YOLO format should be saved. Default is \"\n",
    "        + YOLO_filename,\n",
    "    )\n",
    "\n",
    "    FLAGS = parser.parse_args()\n",
    "\n",
    "    # Prepare the dataset for YOLO\n",
    "    multi_df = pd.read_csv(FLAGS.VoTT_csv)\n",
    "    labels = multi_df[\"label\"].unique()\n",
    "    labeldict = dict(zip(labels, range(len(labels))))\n",
    "    multi_df.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
    "    train_path = FLAGS.VoTT_Folder\n",
    "    convert_vott_csv_to_yolo(\n",
    "        multi_df, labeldict, path=train_path, target_name=FLAGS.YOLO_filename\n",
    "    )\n",
    "\n",
    "    # Make classes file\n",
    "    file = open(classes_filename, \"w\")\n",
    "\n",
    "    # Sort Dict by Values\n",
    "    SortedLabelDict = sorted(labeldict.items(), key=lambda x: x[1])\n",
    "    for elem in SortedLabelDict:\n",
    "        file.write(elem[0] + \"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
